{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ОТЧЕТ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Какое качество получилось у логистической регрессии над всеми исходными признаками? Как оно соотносится с качеством градиентного бустинга? Чем вы можете объяснить эту разницу? Быстрее ли работает логистическая регрессия по сравнению с градиентным бустингом? ####\n",
    "\n",
    "Качество = 0.72\n",
    "Это сравнимо с градиентным бустингом, где количество деревьев превышает 150\n",
    "Логистическая регрессия работает быстрее градиентного бустинга    \n",
    "\n",
    "#### 2. Как влияет на качество логистической регрессии удаление категориальных признаков (укажите новое значение метрики качества)? Чем вы можете объяснить это изменение?\n",
    "\n",
    "Качество после удаления категориальных признаков не изменилось   \n",
    "Следовательно, категориальные признаки не влияли на кросс-валидацию   \n",
    "\n",
    "#### 3. Сколько различных идентификаторов героев существует в данной игре?\n",
    "\n",
    "Всего героев в игре: 112  \n",
    "\n",
    "#### 4. Какое получилось качество при добавлении \"мешка слов\" по героям? Улучшилось ли оно по сравнению с предыдущим вариантом? Чем вы можете это объяснить?\n",
    "\n",
    "0.75. Качество увеличилось.    \n",
    "Как оказалось, категориальных признаки имели большой вес, и стоило не удалять их а зменить на числовые аналоги\n",
    "\n",
    "#### 5. Какое минимальное и максимальное значение прогноза на тестовой выборке получилось у лучшего из алгоритмов?\n",
    "\n",
    "min: 0.5    \n",
    "max: 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подход 2: логистическая регрессия #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint \n",
    "import time\n",
    "import datetime\n",
    "from sklearn.cross_validation import KFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresTrain = pd.read_csv('data/features.csv', index_col='match_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresTrain = featuresTrain.drop([\n",
    "\t\t'duration', \n",
    "\t\t'tower_status_radiant', \n",
    "\t\t'tower_status_dire', \n",
    "\t\t'barracks_status_radiant', \n",
    "\t\t'barracks_status_dire'\n",
    "\t\t], \n",
    "\t\taxis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanEmptyColumn(df):\n",
    "\t# Замена всех пропусков на 0\n",
    "\tdf = df.fillna(0)\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Оцените качество логистической регрессии (sklearn.linear_model.LogisticRegression с L2-регуляризацией) с помощью кросс-валидации по той же схеме, которая использовалась для градиентного бустинга. Подберите при этом лучший параметр регуляризации (C). Какое наилучшее качество у вас получилось? Как оно соотносится с качеством градиентного бустинга? Чем вы можете объяснить эту разницу? Быстрее ли работает логистическая регрессия по сравнению с градиентным бустингом? ###\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticRegression(XTrain, yTrain):\n",
    "\tscaler = StandardScaler()\n",
    "\tXTrain = scaler.fit_transform(XTrain)\n",
    "\tkf = KFold(yTrain.size, n_folds=5, shuffle=True, random_state=241)\n",
    "\tcRange = range(-5, 5)\n",
    "\tfor c in cRange:\n",
    "\t\tc = 10**c\n",
    "\t\tprint('Параметр С: ',c)\n",
    "\t\tmodel = LogisticRegression(penalty='l2', C=c, random_state=241)\n",
    "\t\tstartTime = datetime.datetime.now()\n",
    "\t\tscores = cross_val_score(model, XTrain, yTrain.values.ravel(), cv=kf, scoring='roc_auc')\n",
    "\t\tprint('Время обучения:', datetime.datetime.now() - startTime)\n",
    "\t\tprint(scores)\n",
    "\t\tprint(\"_____\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Параметр С:  1e-05\n",
      "Время обучения: 0:00:02.787864\n",
      "[0.69959206 0.69159358 0.69419291 0.69433159 0.69589176]\n",
      "_____\n",
      "Параметр С:  0.0001\n",
      "Время обучения: 0:00:04.235202\n",
      "[0.7161759  0.7083769  0.70960313 0.71017245 0.71192219]\n",
      "_____\n",
      "Параметр С:  0.001\n",
      "Время обучения: 0:00:07.835058\n",
      "[0.72134945 0.71368677 0.71425051 0.71512064 0.71649386]\n",
      "_____\n",
      "Параметр С:  0.01\n",
      "Время обучения: 0:00:10.239558\n",
      "[0.7216634  0.71377395 0.71440813 0.71540233 0.7164595 ]\n",
      "_____\n",
      "Параметр С:  0.1\n",
      "Время обучения: 0:00:10.822055\n",
      "[0.72165841 0.7137031  0.71438941 0.71539496 0.71640454]\n",
      "_____\n",
      "Параметр С:  1\n",
      "Время обучения: 0:00:10.673508\n",
      "[0.72165762 0.71369565 0.71438656 0.71539329 0.7163998 ]\n",
      "_____\n",
      "Параметр С:  10\n",
      "Время обучения: 0:00:10.653583\n",
      "[0.72165702 0.7136947  0.71438623 0.71539423 0.71639952]\n",
      "_____\n",
      "Параметр С:  100\n",
      "Время обучения: 0:00:10.782558\n",
      "[0.72165734 0.71369455 0.7143859  0.71539408 0.71639946]\n",
      "_____\n",
      "Параметр С:  1000\n",
      "Время обучения: 0:00:10.714921\n",
      "[0.72165734 0.71369457 0.71438593 0.71539409 0.71639938]\n",
      "_____\n",
      "Параметр С:  10000\n",
      "Время обучения: 0:00:10.609480\n",
      "[0.72165733 0.71369457 0.71438593 0.71539407 0.71639938]\n",
      "_____\n"
     ]
    }
   ],
   "source": [
    "trainData = cleanEmptyColumn(featuresTrain)\n",
    "XTrain = trainData.drop('radiant_win',1)\n",
    "yTrain = trainData['radiant_win'].to_frame()\n",
    "logisticRegression(XTrain,yTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ОТВЕТ:     ####\n",
    "С = 0.01 - лучший парамерр регуляризации   \n",
    "Качество = 0.72\n",
    "\n",
    "Это сравнимо с градиентным бустингом, где количество деревьев превышает 150   \n",
    "Логистическая регрессия работает быстрее градиентного бустинга"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Среди признаков в выборке есть категориальные, которые мы использовали как числовые, что вряд ли является хорошей идеей. Категориальных признаков в этой задаче одиннадцать: lobby_type и r1_hero, r2_hero, ..., r5_hero, d1_hero, d2_hero, ..., d5_hero. Уберите их из выборки, и проведите кросс-валидацию для логистической регрессии на новой выборке с подбором лучшего параметра регуляризации. Изменилось ли качество? Чем вы можете это объяснить? ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanCategory(X):\n",
    "    X.drop('lobby_type',1)\n",
    "    X.drop('r1_hero',1)\n",
    "    X.drop('r2_hero',1)\n",
    "    X.drop('r3_hero',1)\n",
    "    X.drop('r4_hero',1)\n",
    "    X.drop('r5_hero',1)\n",
    "    X.drop('d1_hero',1)\n",
    "    X.drop('d2_hero',1)\n",
    "    X.drop('d3_hero',1)\n",
    "    X.drop('d4_hero',1)\n",
    "    X.drop('d5_hero',1)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain = cleanCategory(XTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Параметр С:  1e-05\n",
      "Время обучения: 0:00:02.784535\n",
      "[0.69959206 0.69159358 0.69419291 0.69433159 0.69589176]\n",
      "_____\n",
      "Параметр С:  0.0001\n",
      "Время обучения: 0:00:04.266154\n",
      "[0.7161759  0.7083769  0.70960313 0.71017245 0.71192219]\n",
      "_____\n",
      "Параметр С:  0.001\n",
      "Время обучения: 0:00:07.813465\n",
      "[0.72134945 0.71368677 0.71425051 0.71512064 0.71649386]\n",
      "_____\n",
      "Параметр С:  0.01\n",
      "Время обучения: 0:00:10.166956\n",
      "[0.7216634  0.71377395 0.71440813 0.71540233 0.7164595 ]\n",
      "_____\n",
      "Параметр С:  0.1\n",
      "Время обучения: 0:00:10.589582\n",
      "[0.72165841 0.7137031  0.71438941 0.71539496 0.71640454]\n",
      "_____\n",
      "Параметр С:  1\n",
      "Время обучения: 0:00:10.593966\n",
      "[0.72165762 0.71369565 0.71438656 0.71539329 0.7163998 ]\n",
      "_____\n",
      "Параметр С:  10\n",
      "Время обучения: 0:00:10.685891\n",
      "[0.72165702 0.7136947  0.71438623 0.71539423 0.71639952]\n",
      "_____\n",
      "Параметр С:  100\n",
      "Время обучения: 0:00:10.665709\n",
      "[0.72165734 0.71369455 0.7143859  0.71539408 0.71639946]\n",
      "_____\n",
      "Параметр С:  1000\n",
      "Время обучения: 0:00:10.687510\n",
      "[0.72165734 0.71369457 0.71438593 0.71539409 0.71639938]\n",
      "_____\n",
      "Параметр С:  10000\n",
      "Время обучения: 0:00:10.704975\n",
      "[0.72165733 0.71369457 0.71438593 0.71539407 0.71639938]\n",
      "_____\n"
     ]
    }
   ],
   "source": [
    "logisticRegression(XTrain,yTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ОТВЕТ ####\n",
    "Качество после удаления категориальных признаков не изменилось      \n",
    "Следовательно, категориальные признаки не влияли на кросс-валидацию "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. На предыдущем шаге мы исключили из выборки признаки rM_hero и dM_hero, которые показывают, какие именно герои играли за каждую команду. Это важные признаки — герои имеют разные характеристики, и некоторые из них выигрывают чаще, чем другие. Выясните из данных, сколько различных идентификаторов героев существует в данной игре (вам может пригодиться фукнция unique или value_counts). ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numHeroes(heroes):\n",
    "\tprint('Всего героев в игре:', len(heroes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего героев в игре: 112\n"
     ]
    }
   ],
   "source": [
    "heroes = pd.read_csv('data/dictionaries/heroes.csv')\n",
    "numHeroes(heroes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Воспользуемся подходом \"мешок слов\" для кодирования информации о героях. Пусть всего в игре имеет N различных героев. Сформируем N признаков, при этом i-й будет равен нулю, если i-й герой не участвовал в матче; единице, если i-й герой играл за команду Radiant; минус единице, если i-й герой играл за команду Dire. Ниже вы можете найти код, который выполняет данной преобразование. Добавьте полученные признаки к числовым, которые вы использовали во втором пункте данного этапа. ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = heroes.shape[0]\n",
    "X_pick = np.zeros((XTrain.shape[0], N))\n",
    "\n",
    "for i, match_id in enumerate(XTrain.index):\n",
    "    for p in range(5):\n",
    "        X_pick[i, XTrain.loc[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, XTrain.loc[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Проведите кросс-валидацию для логистической регрессии на новой выборке с подбором лучшего параметра регуляризации. Какое получилось качество? Улучшилось ли оно? Чем вы можете это объяснить? ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Параметр С:  1e-05\n",
      "Время обучения: 0:00:06.483176\n",
      "[0.71902994 0.71120697 0.71507984 0.71291814 0.71598965]\n",
      "_____\n",
      "Параметр С:  0.0001\n",
      "Время обучения: 0:00:09.123991\n",
      "[0.74673258 0.74001936 0.74260214 0.74026026 0.74430669]\n",
      "_____\n",
      "Параметр С:  0.001\n",
      "Время обучения: 0:00:15.020139\n",
      "[0.75503591 0.74925153 0.75165321 0.74902422 0.75306145]\n",
      "_____\n",
      "Параметр С:  0.01\n",
      "Время обучения: 0:00:20.590198\n",
      "[0.75509143 0.74979078 0.75201826 0.74951065 0.75309794]\n",
      "_____\n",
      "Параметр С:  0.1\n",
      "Время обучения: 0:00:21.875238\n",
      "[0.75500689 0.74982166 0.75197248 0.74953636 0.75294704]\n",
      "_____\n",
      "Параметр С:  1\n",
      "Время обучения: 0:00:22.941993\n",
      "[0.75499645 0.74982521 0.75196506 0.74953762 0.75292372]\n",
      "_____\n",
      "Параметр С:  10\n",
      "Время обучения: 0:00:24.560011\n",
      "[0.75499654 0.74982551 0.75196402 0.74953846 0.75292095]\n",
      "_____\n",
      "Параметр С:  100\n",
      "Время обучения: 0:00:25.426653\n",
      "[0.75499658 0.74982553 0.75196381 0.74953847 0.7529206 ]\n",
      "_____\n",
      "Параметр С:  1000\n",
      "Время обучения: 0:00:24.773514\n",
      "[0.7549965  0.74982559 0.75196385 0.74953845 0.75292055]\n",
      "_____\n",
      "Параметр С:  10000\n",
      "Время обучения: 0:00:24.591754\n",
      "[0.75499651 0.74982558 0.75196386 0.74953845 0.75292052]\n",
      "_____\n"
     ]
    }
   ],
   "source": [
    "X_pick_transp = np.transpose(X_pick)\n",
    "for i in range(0, N):\n",
    "    XTrain[\"bow_\"+str(i)] = pd.Series(X_pick_transp[i], index=XTrain.index)\n",
    "    \n",
    "logisticRegression(XTrain,yTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ОТВЕТ ####\n",
    "\n",
    "0.75. Качество увеличилось. Как оказалось, категориальных признаки имели большой вес, и стоило не удалять их а зменить на числовые аналоги"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Постройте предсказания вероятностей победы команды Radiant для тестовой выборки с помощью лучшей из изученных моделей (лучшей с точки зрения AUC-ROC на кросс-валидации). Убедитесь, что предсказанные вероятности адекватные — находятся на отрезке [0, 1], не совпадают между собой (т.е. что модель не получилась константной). ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min 0.49999999996770517\n",
      "max 0.5000000000139433\n"
     ]
    }
   ],
   "source": [
    "featuresTest = pd.read_csv('data/features_test.csv', index_col='match_id')\n",
    "X_pick = np.zeros((featuresTest.shape[0], N))\n",
    "for i, match_id in enumerate(featuresTest.index):\n",
    "    for p in range(5):\n",
    "        X_pick[i, featuresTest.loc[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, featuresTest.loc[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "        \n",
    "X = cleanCategory(featuresTest)\n",
    "\n",
    "X_pick_transp = np.transpose(X_pick)\n",
    "for i in range(0, N):\n",
    "    X[\"bow_\"+str(i)] = pd.Series(X_pick_transp[i], index=XTest.index)\n",
    "\n",
    "X = cleanEmptyColumn(X)\n",
    "scaler = StandardScaler()\n",
    "XTest = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "model = LogisticRegression(penalty='l2', C=c, random_state=241)\n",
    "model.fit(XTrain,yTrain.values.ravel())\n",
    "\n",
    "probPos = model.predict_proba(XTest)\n",
    "    \n",
    "print('min ' + str(min(probPos[:, 1])))\n",
    "print('max ' + str(max(probPos[:, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
